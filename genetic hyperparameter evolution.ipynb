{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 train samples\n",
      "1000 test samples\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 2\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train[:2000].reshape(2000, 784)\n",
    "x_test = x_test[2000:3000].reshape(1000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train[:2000], num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test[2000:3000], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x_train, y_train, x_test, y_test, d_1, d_2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(d_1, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(d_2, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return float(score[0])    #this float is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_283 (Dense)            (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 16,020\n",
      "Trainable params: 16,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 2.2029 - acc: 0.2245 - val_loss: 2.0891 - val_acc: 0.2570\n",
      "Epoch 2/2\n",
      "2000/2000 [==============================] - 0s 53us/step - loss: 1.9658 - acc: 0.3055 - val_loss: 1.9094 - val_acc: 0.3000\n",
      "Test loss: 1.9094392070770263\n",
      "Test accuracy: 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9094392070770263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nevergrad import instrumentation as instru\n",
    "\n",
    "def myfunction(arg1, arg2, arg3, value=3):\n",
    "    print(arg1, arg2, arg3)\n",
    "    return value**2\n",
    "\n",
    "# argument transformation\n",
    "first_dense_neurons = instru.variables.OrderedDiscrete([10, 20])  # neurons of the first dense layer\n",
    "second_dense_neurons = instru.variables.OrderedDiscrete([10, 30])  # 1st arg. = positional discrete argument\n",
    "dropout_rate = instru.variables.OrderedDiscrete([0, 0.2, 0.6])  # 2nd arg. = positional discrete argument\n",
    "\n",
    "# create the instrumented function\n",
    "ifunc = instru.InstrumentedFunction(network, x_train, y_train, x_test, y_test,\n",
    "                                    first_dense_neurons, second_dense_neurons)\n",
    "# the 3rd arg. is a positional arg. which will be kept constant to \"blublu\"\n",
    "print(ifunc.dimension)  # 5 dimensional space\n",
    "\n",
    "# The dimension is 5 because:\n",
    "# - the 1st discrete variable has 1 possible values, represented by a hard thresholding in a 1-dimensional space, i.e. we add 1 coordinate to the continuous problem\n",
    "# - the 2nd discrete variable has 3 possible values, represented by softmax, i.e. we add 3 coordinates to the continuous problem\n",
    "# - the 3rd variable has no uncertainty, so it does not introduce any coordinate in the continuous problem\n",
    "# - the 4th variable is a real number, represented by single coordinate.\n",
    "\n",
    "ifunc([1, -80])  # will print \"b e blublu\" and return 49 = (mean + std * arg)**2 = (1 + 2 * 3)**2\n",
    "# b is selected because 1 > 0 (the threshold is 0 here since there are 2 values.\n",
    "# e is selected because proba(e) = exp(80) / (exp(80) + exp(-80) + exp(-80))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnot ask and tell\\n\\n\\nfrom nevergrad.optimization import optimizerlib\\n\\noptimizer = optimizerlib.CMA(dimension=2, budget=5, num_workers=1)\\n\\nfrom concurrent import futures\\n\\nwith futures.ThreadPoolExecutor(max_workers=optimizer.num_workers) as executor:\\n    recommendation = optimizer.optimize(ifunc, executor=executor, batch_mode=True)\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "not ask and tell\n",
    "\n",
    "\n",
    "from nevergrad.optimization import optimizerlib\n",
    "\n",
    "optimizer = optimizerlib.CMA(dimension=2, budget=5, num_workers=1)\n",
    "\n",
    "from concurrent import futures\n",
    "\n",
    "with futures.ThreadPoolExecutor(max_workers=optimizer.num_workers) as executor:\n",
    "    recommendation = optimizer.optimize(ifunc, executor=executor, batch_mode=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "X:  [ 0.62114414 -0.8178619 ]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_286 (Dense)            (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 16,020\n",
      "Trainable params: 16,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 2.0553 - acc: 0.2775 - val_loss: 1.9029 - val_acc: 0.4040\n",
      "Epoch 2/2\n",
      "2000/2000 [==============================] - 0s 53us/step - loss: 1.6213 - acc: 0.5675 - val_loss: 1.6091 - val_acc: 0.5480\n",
      "Test loss: 1.6091353273391724\n",
      "Test accuracy: 0.548\n",
      "value:  1.6091353273391724\n",
      "optimizer:  Instance of CMA(dimension=2, budget=5, num_workers=1)\n",
      "epoch:  1\n",
      "X:  [ 0.42908209 -0.17577748]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_289 (Dense)            (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 16,020\n",
      "Trainable params: 16,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 2.0285 - acc: 0.3380 - val_loss: 1.9077 - val_acc: 0.4110\n",
      "Epoch 2/2\n",
      "2000/2000 [==============================] - 0s 55us/step - loss: 1.6535 - acc: 0.4935 - val_loss: 1.6501 - val_acc: 0.4930\n",
      "Test loss: 1.6501346292495727\n",
      "Test accuracy: 0.493\n",
      "value:  1.6501346292495727\n",
      "optimizer:  Instance of CMA(dimension=2, budget=5, num_workers=1)\n",
      "epoch:  2\n",
      "X:  [1.23183705 0.60201125]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_292 (Dense)            (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 30)                630       \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 16,640\n",
      "Trainable params: 16,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 2.0164 - acc: 0.3580 - val_loss: 1.8432 - val_acc: 0.4610\n",
      "Epoch 2/2\n",
      "2000/2000 [==============================] - 0s 54us/step - loss: 1.5106 - acc: 0.6185 - val_loss: 1.4730 - val_acc: 0.6010\n",
      "Test loss: 1.4730060062408448\n",
      "Test accuracy: 0.601\n",
      "value:  1.4730060062408448\n",
      "optimizer:  Instance of CMA(dimension=2, budget=5, num_workers=1)\n",
      "epoch:  3\n",
      "X:  [ 1.39263483 -0.62586463]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_295 (Dense)            (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 16,020\n",
      "Trainable params: 16,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 2.0940 - acc: 0.1900 - val_loss: 1.9612 - val_acc: 0.2280\n",
      "Epoch 2/2\n",
      "2000/2000 [==============================] - 0s 54us/step - loss: 1.8167 - acc: 0.3040 - val_loss: 1.7945 - val_acc: 0.3250\n",
      "Test loss: 1.7945231838226319\n",
      "Test accuracy: 0.325\n",
      "value:  1.7945231838226319\n",
      "optimizer:  Instance of CMA(dimension=2, budget=5, num_workers=1)\n",
      "epoch:  4\n",
      "X:  [ 1.79304268 -0.05337398]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_298 (Dense)            (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 16,020\n",
      "Trainable params: 16,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 2.0753 - acc: 0.1695 - val_loss: 1.9642 - val_acc: 0.2620\n",
      "Epoch 2/2\n",
      "2000/2000 [==============================] - 0s 55us/step - loss: 1.7985 - acc: 0.3300 - val_loss: 1.7738 - val_acc: 0.3410\n",
      "Test loss: 1.773842755317688\n",
      "Test accuracy: 0.341\n",
      "value:  1.773842755317688\n",
      "optimizer:  Instance of CMA(dimension=2, budget=5, num_workers=1)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(optimizer.budget):\n",
    "    print('epoch: ', _)\n",
    "    x = optimizer.ask()\n",
    "    print('X: ', x)\n",
    "    value = ifunc(x)\n",
    "    print('value: ', value)\n",
    "    optimizer.tell(x, value)\n",
    "    print('optimizer: ', optimizer)\n",
    "\n",
    "recommendation = optimizer.provide_recommendation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7408146354361135, 0.5331237899686446)\n"
     ]
    }
   ],
   "source": [
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_301 (Dense)            (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 30)                630       \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 16,640\n",
      "Trainable params: 16,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 2.0320 - acc: 0.3235 - val_loss: 1.8295 - val_acc: 0.4320\n",
      "Epoch 2/2\n",
      "2000/2000 [==============================] - 0s 53us/step - loss: 1.5732 - acc: 0.6080 - val_loss: 1.4507 - val_acc: 0.6380\n",
      "Test loss: 1.4506826238632202\n",
      "Test accuracy: 0.638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4506826238632202"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ifunc(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
